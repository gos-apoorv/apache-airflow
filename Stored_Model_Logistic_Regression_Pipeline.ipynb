{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gos-apoorv/apache-airflow/blob/main/Stored_Model_Logistic_Regression_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh5GpErxAHrb",
        "outputId": "633bd7ca-13e3-421b-9410-35a2833ea4f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "content_path = '/content/drive'\n",
        "drive.mount(content_path)\n",
        "drive_path = content_path + '/MyDrive/geocoding'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvTmd6ccAHu7",
        "outputId": "c6335063-6b3f-40e2-d9b2-3c5a440ea66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████▎                        | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 20 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 30 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 40 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 44 kB 2.9 MB/s \n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3M\t/content/drive/MyDrive/geocoding/cache\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1102"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%pip -qq install diskcache \n",
        "import diskcache as dc\n",
        "\n",
        "import os\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import json\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "!du -h --max-depth=1 {drive_path}/cache\n",
        "cache = dc.Cache(drive_path+'/cache')\n",
        "cache.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u03d7kdEAH06",
        "outputId": "25bede73-dae7-4c23-b13f-08311fa4b7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "# BQ client for BQ data queries\n",
        "from google.cloud import bigquery\n",
        "bq_client = bigquery.Client(project=\"gelato-data-warehouse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcHKSbDlAH3u"
      },
      "outputs": [],
      "source": [
        "from hashlib import md5\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def get_cached_df_path(cid):\n",
        "  return f\"{content_path}/MyDrive/pandas_cache/{cid}.pk\"\n",
        "\n",
        "def get_cached_df(cid):\n",
        "  path = get_cached_df_path(cid)\n",
        "  if os.path.exists(path):\n",
        "    return pd.read_pickle(path)\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "def set_cached_df(cid, df):\n",
        "  path = get_cached_df_path(cid)\n",
        "  os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "  df.to_pickle(path)\n",
        "\n",
        "def cached_query(query:str, client: bigquery.client, cache: bool = True, cid: str = None) -> pd.DataFrame:\n",
        "  if cid is None:\n",
        "    cid = md5(query.encode()).hexdigest()\n",
        "\n",
        "  if cache:\n",
        "    cached_df = get_cached_df(cid)\n",
        "    if cached_df is not None:\n",
        "      return cached_df\n",
        "\n",
        "  query_job = client.query(query)\n",
        "  df = query_job.result().to_dataframe()\n",
        "\n",
        "  if cache:\n",
        "    set_cached_df(cid, df)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMoWOEuHAlD8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMA-oS3XqQKh"
      },
      "source": [
        "# Get Data For Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX0Gd9n8qPjM"
      },
      "outputs": [],
      "source": [
        "df_prediction = cached_query(\"\"\"\n",
        "WITH network_print_job AS (select job.*, package.client_id\n",
        "      from pgsql_printcloud_view.public_print_job as job\n",
        "      join pgsql_printcloud_view.public_package as package\n",
        "        on job.package_id = package.package_id\n",
        "      where\n",
        "        date(job.created_at) >=\n",
        "        date_trunc(date_add(current_date(), interval -2 year), year)\n",
        "\n",
        "    )\n",
        "  ,  platform_product AS (select\n",
        "        product.*,\n",
        "        replace(model.description, ' product', '') as commercial_product\n",
        "\n",
        "      from pgsql_product_platform_view.list_product as product\n",
        "      left join pgsql_product_platform_view.model_model as model\n",
        "        on product.product_model_uid = model.id\n",
        "\n",
        "    )\n",
        "  ,  network_product_mapping_groups AS (select distinct\n",
        "        product.product_uid,\n",
        "        pgroups.product_group\n",
        "\n",
        "      from platform_product as product\n",
        "      join google_sheets_us.network_product_mapping_groups as pgroups\n",
        "        on product.product_uid like concat(pgroups.product_uid_starts, '%')\n",
        "\n",
        "    )\n",
        "  ,  network_print_job_event AS (select\n",
        "        hist.*,\n",
        "        curr.last_event_at,\n",
        "        package.order_date as ordered_at,\n",
        "        package_dates.promised_min_dispatch_date as min_dispatch_promised_at,\n",
        "        package_dates.promised_delivery_max_date as delivery_max_promised_at,\n",
        "        package_dates.promised_delivery_min_date as delivery_min_promised_at\n",
        "\n",
        "      from (\n",
        "        select\n",
        "          print_job_id,\n",
        "          max(case when status_id = 16 then created_at else null end) as uploading_to_storage_at,\n",
        "          max(case when status_id = 3 then created_at else null end) as failed_at,\n",
        "          max(case when status_id = 1 then created_at else null end) as new_at,\n",
        "          max(case when status_id = 4 then created_at else null end) as prepared_at,\n",
        "          max(case when status_id = 5 then created_at else null end) as printed_at,\n",
        "          max(case when status_id = 6 then created_at else null end) as shipped_at,\n",
        "          min(case when status_id = 6 then created_at else null end) as scanned_at,\n",
        "          max(case when status_id = 17 then created_at else null end) as cancelled_at,\n",
        "          min(case when status_id = 19 then created_at else null end) as in_transit_at,\n",
        "          max(case when status_id = 21 then created_at else null end) as delivered_at\n",
        "\n",
        "          from pgsql_printcloud_view.public_print_job_status_log\n",
        "          group by 1\n",
        "      ) as hist\n",
        "\n",
        "      left join (\n",
        "        select\n",
        "          print_job_id,\n",
        "          created_at as last_event_at\n",
        "            from (\n",
        "              select\n",
        "                print_job_id,\n",
        "                created_at,\n",
        "                row_number() over (partition by print_job_id order by created_at desc) as event_order\n",
        "\n",
        "              from pgsql_printcloud_view.public_print_job_status_log\n",
        "            )\n",
        "        where event_order = 1\n",
        "      ) as curr\n",
        "\n",
        "      on hist.print_job_id = curr.print_job_id\n",
        "\n",
        "      left join pgsql_printcloud_view.public_print_job as job\n",
        "        on hist.print_job_id = job.print_job_id\n",
        "\n",
        "      left join pgsql_printcloud_view.public_package as package\n",
        "        on job.package_id = package.package_id\n",
        "\n",
        "      left join pgsql_printcloud_view.public_package_dispatch_date as package_dates\n",
        "        on package.package_id = package_dates.package_id\n",
        "\n",
        "    )\n",
        "  ,  network_package AS (select\n",
        "        package.*,\n",
        "        security_client.client_type\n",
        "\n",
        "      from pgsql_printcloud_view.public_package as package\n",
        "      left join pgsql_printcloud_view.security_client as security_client\n",
        "        on package.client_id = security_client.client_id\n",
        "\n",
        "    )\n",
        "  ,  tracking_package AS (select * from tracking_service.tracking_package_tracking\n",
        "      where DeletedAt is null\n",
        "\n",
        "    )\n",
        "  ,  tracking_trail AS (select * from tracking_service.tracking_audit_trail\n",
        "      where DeletedAt is null\n",
        "\n",
        "    )\n",
        "  ,  tracking_status_log AS (select\n",
        "        log.*,\n",
        "        packages.PackageID,\n",
        "        case log.StatusUID\n",
        "          when 0 then 'Registered'\n",
        "          when 1 then 'In Transit'\n",
        "          when 2 then 'Out for Delivery'\n",
        "          when 3 then 'Failed Attempt'\n",
        "          when 4 then 'Shipping Exception'\n",
        "          when 5 then 'Available for Pickup'\n",
        "          when 6 then 'Delivered'\n",
        "          when 7 then 'Dispatched'\n",
        "          when 8 then 'Returned'\n",
        "          else 'Other'\n",
        "        end as Status,\n",
        "        ROW_NUMBER() over (PARTITION BY packages.PackageID ORDER BY log.ThirdPartyEventAt) as log_rank,\n",
        "        case\n",
        "        when DATE_DIFF(lead(log.ThirdPartyEventAt,1) OVER (PARTITION BY packages.PackageID ORDER BY log.ThirdPartyEventAt),log.ThirdPartyEventAt,second)/3600 is null and log.StatusUID !=6\n",
        "          then timestamp_diff(current_timestamp(),log.ThirdPartyEventAt,hour)\n",
        "        else DATE_DIFF(lead(log.ThirdPartyEventAt,1) OVER (PARTITION BY packages.PackageID ORDER BY log.ThirdPartyEventAt),log.ThirdPartyEventAt,second)/3600\n",
        "        end as time_spent\n",
        "          from tracking_service.tracking_package_tracking as packages\n",
        "        join tracking_service.tracking_audit_trail as trails\n",
        "          on packages.ID = trails.PackageTrackingID and\n",
        "             trails.DeletedAt is null\n",
        "        join tracking_service.tracking_audit_trail_status_log as log\n",
        "          on trails.ID = log.AuditTrailID and\n",
        "             log.DeletedAt is null\n",
        "\n",
        "    )\n",
        "  ,  tracking_status_log_min_delivered_date AS (select\n",
        "            a.PackageID,\n",
        "            a.min_event_date_delivered\n",
        "          from\n",
        "          (select\n",
        "            PackageID,\n",
        "            min(ThirdPartyEventAt) as min_event_date_delivered\n",
        "           from tracking_status_log\n",
        "            where\n",
        "              Status = 'Available for Pickup' OR Status = 'Delivered'\n",
        "             group by 1) a )\n",
        "  ,  tracking_status_log_min_date_in_transit AS (select\n",
        "            a.PackageID,\n",
        "            a.min_event_date_in_transit\n",
        "          from\n",
        "          (select\n",
        "            PackageID,\n",
        "            min(ThirdPartyEventAt) as min_event_date_in_transit\n",
        "           from tracking_status_log\n",
        "            where\n",
        "              Status = 'In Transit'\n",
        "             group by 1) a )\n",
        "  ,  tracking_status_log_min_date_out_for_delivery AS (select\n",
        "            a.PackageID,\n",
        "            a.min_event_date_out_for_delivery\n",
        "          from\n",
        "          (select\n",
        "            PackageID,\n",
        "            min(ThirdPartyEventAt) as min_event_date_out_for_delivery\n",
        "           from tracking_status_log\n",
        "            where\n",
        "              Status = 'Out for Delivery'\n",
        "             group by 1) a )\n",
        "  ,  shipment_method AS (select *\n",
        "      from pgsql_shipment_service_view.public_methods\n",
        "      --where is_enabled\n",
        "      --DBI 1236: blanks were coming up for previous orders\n",
        "    )\n",
        "  ,  shipment_zone_postcode_range AS (select\n",
        "        p.*,\n",
        "        z.country_id,\n",
        "        z.has_postcode_range,\n",
        "\n",
        "        --06-Apr-2022 Mahesh: Added for transit time analysis\n",
        "        c.title         as print_house,\n",
        "        d.title         as shipment_method_name,\n",
        "        e.title         as shipment_provider_name\n",
        "\n",
        "      from pgsql_shipment_service_view.prices_shipment_zone_postcode_range as p\n",
        "      left join pgsql_shipment_service_view.prices_shipment_country_zone as z\n",
        "      on p.shipment_country_zone_id = z.shipment_country_zone_id\n",
        "\n",
        "      left join pgsql_shipment_service_view.prices_shipment_delivery_information as b\n",
        "      on z.shipment_country_zone_id = b.shipment_country_zone_id\n",
        "\n",
        "      left join pgsql_shipment_service_view.public_locations as c on\n",
        "      b.location_id = c.location_id\n",
        "\n",
        "      left join pgsql_shipment_service_view.public_methods as d on\n",
        "      b.method_id = d.method_id\n",
        "\n",
        "      left join pgsql_shipment_service_view.public_providers as e on\n",
        "      d.provider_id = e.provider_id\n",
        "    )\n",
        "  ,  shipment_country_zone AS (select\n",
        "        a.*,\n",
        "        c.title         as print_house,\n",
        "        d.title         as shipment_method_name,\n",
        "        e.title         as shipment_provider_name,\n",
        "        f.iso_code      as Zone_Country_Id\n",
        "      from\n",
        "          pgsql_shipment_service_view.prices_shipment_country_zone as a\n",
        "          left join pgsql_shipment_service_view.prices_shipment_delivery_information as b\n",
        "          on a.shipment_country_zone_id = b.shipment_country_zone_id\n",
        "\n",
        "          left join pgsql_shipment_service_view.public_locations as c on\n",
        "          b.location_id = c.location_id\n",
        "\n",
        "          left join pgsql_shipment_service_view.public_methods as d on\n",
        "          b.method_id = d.method_id\n",
        "\n",
        "          left join pgsql_shipment_service_view.public_providers as e on\n",
        "          d.provider_id = e.provider_id\n",
        "\n",
        "          left join pgsql_shipment_service_view.public_countries as f on\n",
        "          a.country_id = f.country_id\n",
        "    )\n",
        "SELECT\n",
        "    (MOD((EXTRACT(DAYOFWEEK FROM TIMESTAMP(FORMAT_TIMESTAMP('%F %X', timestamp(datetime(network_package.order_date),'UTC'), network_print_house.time_zone)) ) - 1) - 1 + 7, 7)) AS network_package_order_local_day_of_week_index,\n",
        "        (FORMAT_TIMESTAMP('%A', TIMESTAMP(FORMAT_TIMESTAMP('%F %X', timestamp(datetime(network_package.order_date),'UTC'), network_print_house.time_zone)) )) AS network_package_order_local_day_of_week,\n",
        "    network_print_house.name  AS network_print_house_name,\n",
        "    shipment_country_zone.shipment_method_name  AS shipment_country_zone_zone_shipment_method_name,\n",
        "    (case\n",
        "\n",
        "        when network_product_mapping_groups.product_uid like 'flat_product%' then\n",
        "          if(\n",
        "             network_product_mapping_groups.product_uid like '%_a5_%' or\n",
        "             network_product_mapping_groups.product_uid like '%_a6_%' or\n",
        "             network_product_mapping_groups.product_uid like '%_sx_%' or\n",
        "             network_product_mapping_groups.product_uid like '%_lt_%' or\n",
        "             network_product_mapping_groups.product_uid like '%_dl_%' or\n",
        "             network_product_mapping_groups.product_uid like '%_a4_pt_90-gsm%' or\n",
        "             network_product_mapping_groups.product_uid like '%_a4_pt_150-gsm%' or\n",
        "             network_product_mapping_groups.product_uid like '%_a4_pt_300-gsm%' or\n",
        "             network_product_mapping_groups.product_uid like '%sm_pt_80-lb%' or\n",
        "             network_product_mapping_groups.product_uid like '%sm_pt_100-lb%' or\n",
        "             network_product_mapping_groups.product_uid like '%sm_pt_130-lb%' or\n",
        "             network_product_mapping_groups.product_uid like '%5r_pt_100-lb%' or\n",
        "             network_product_mapping_groups.product_uid like '%5r_pt_110-lb%' or\n",
        "             network_product_mapping_groups.product_uid like '%5r_pt_130-lb%' or\n",
        "             network_product_mapping_groups.product_uid like '%5r_pt_90-gsm%' or\n",
        "             network_product_mapping_groups.product_uid like '%5r_pt_150-gsm%' or\n",
        "             network_product_mapping_groups.product_uid like '%5r_pt_300-gsm%' or\n",
        "             network_product_mapping_groups.product_uid like '%_4x9-inch_%' or\n",
        "             network_product_mapping_groups.product_uid like '%_140x180-mm_%' or\n",
        "             network_product_mapping_groups.product_uid like '%_sq_%' or\n",
        "             network_product_mapping_groups.product_uid like '%_bx_%',\n",
        "             'Cards',\n",
        "            'Posters'\n",
        "          )\n",
        "\n",
        "        when network_product_mapping_groups.product_uid like 'flat_product%' then\n",
        "          if(\n",
        "            network_product_mapping_groups.product_uid like '%170-gsm%' or\n",
        "            network_product_mapping_groups.product_uid like '%200-gsm%' or\n",
        "            network_product_mapping_groups.product_uid like '%250-gsm-uncoated-offwhite-archival%' or\n",
        "            network_product_mapping_groups.product_uid like '%65-lb%' or\n",
        "            network_product_mapping_groups.product_uid like '%80-lb%' or\n",
        "            network_product_mapping_groups.product_uid like '%100-lb-cover-uncoated-offwhite-archival%',\n",
        "            'Posters',\n",
        "            'Cards'\n",
        "          )\n",
        "\n",
        "        when network_product_mapping_groups.product_uid like 'flyers%' then\n",
        "          if(\n",
        "            network_product_mapping_groups.product_uid like '%_a5_%' or\n",
        "            network_product_mapping_groups.product_uid like '%_dl_%' or\n",
        "            network_product_mapping_groups.product_uid like '%_a6_%' or\n",
        "            network_product_mapping_groups.product_uid like '%_a4_pt_90-gsm%' or\n",
        "            network_product_mapping_groups.product_uid like '%_a4_pt_150-gsm%' or\n",
        "            network_product_mapping_groups.product_uid like '%_a4_pt_300-gsm%',\n",
        "             'Cards',\n",
        "            'Posters'\n",
        "          )\n",
        "\n",
        "        when network_product_mapping_groups.product_uid like 'flyers%' then\n",
        "          if(\n",
        "            network_product_mapping_groups.product_uid like '%170-gsm%' or\n",
        "            network_product_mapping_groups.product_uid like '%200-gsm%' or\n",
        "            network_product_mapping_groups.product_uid like '%250-gsm-uncoated-offwhite-archival%' or\n",
        "            network_product_mapping_groups.product_uid like '%65-lb%' or\n",
        "            network_product_mapping_groups.product_uid like '%80-lb%' or\n",
        "             network_product_mapping_groups.product_uid like '%100-lb-cover-uncoated-offwhite-archival%',\n",
        "            'Posters',\n",
        "            'Cards'\n",
        "          )\n",
        "\n",
        "        when network_product_mapping_groups.product_uid like 'cards%' then\n",
        "          if(\n",
        "            network_product_mapping_groups.product_uid like '%170-gsm%' or\n",
        "            network_product_mapping_groups.product_uid like '%200-gsm%' or\n",
        "            network_product_mapping_groups.product_uid like '%250-gsm-uncoated-offwhite-archival%' or\n",
        "            network_product_mapping_groups.product_uid like '%65-lb%' or\n",
        "            network_product_mapping_groups.product_uid like '%80-lb%' or\n",
        "             network_product_mapping_groups.product_uid like '%100-lb-cover-uncoated-offwhite-archival%',\n",
        "            'Posters',\n",
        "            'Cards'\n",
        "          )\n",
        "\n",
        "        else ifnull(network_product_mapping_groups.product_group, 'Other')\n",
        "\n",
        "      end) AS network_product_mapping_groups_product_group,\n",
        "        (DATE(case\n",
        "\n",
        "        when\n",
        "\n",
        "          (network_print_job_event.shipped_at = network_print_job_event.last_event_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at >= network_print_job_event.printed_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.shipped_at >= network_print_job_event.prepared_at))\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.prepared_at is null))\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.delivered_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.in_transit_at)\n",
        "\n",
        "        then network_print_job_event.shipped_at\n",
        "\n",
        "        else null\n",
        "\n",
        "      end\n",
        "\n",
        "    )) AS network_print_job_event_shipped_date,\n",
        "    shipment_method.shipping_type  AS shipment_method_shipping_type,\n",
        "    shipment_country_zone.name  AS shipment_country_zone_zone_name,\n",
        "    network_shipment_data_country.emoji  AS network_shipment_data_country_emoji,\n",
        "    network_shipment_data_country.country_name  AS network_shipment_data_country_country_name,\n",
        "        (MOD((EXTRACT(DAYOFWEEK FROM case\n",
        "\n",
        "        when\n",
        "\n",
        "          (network_print_job_event.shipped_at = network_print_job_event.last_event_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at >= network_print_job_event.printed_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.shipped_at >= network_print_job_event.prepared_at))\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.prepared_at is null))\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.delivered_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.in_transit_at)\n",
        "\n",
        "        then network_print_job_event.shipped_at\n",
        "\n",
        "        else null\n",
        "\n",
        "      end\n",
        "\n",
        "    ) - 1) - 1 + 7, 7)) AS network_print_job_event_shipped_day_of_week_index,\n",
        "        (FORMAT_TIMESTAMP('%A', case\n",
        "\n",
        "        when\n",
        "\n",
        "          (network_print_job_event.shipped_at = network_print_job_event.last_event_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at >= network_print_job_event.printed_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.shipped_at >= network_print_job_event.prepared_at))\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.prepared_at is null))\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.delivered_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.in_transit_at)\n",
        "\n",
        "        then network_print_job_event.shipped_at\n",
        "\n",
        "        else null\n",
        "\n",
        "      end\n",
        "\n",
        "    )) AS network_print_job_event_shipped_day_of_week,\n",
        "        (EXTRACT(HOUR FROM case\n",
        "\n",
        "        when\n",
        "\n",
        "          (network_print_job_event.shipped_at = network_print_job_event.last_event_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at >= network_print_job_event.printed_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.shipped_at >= network_print_job_event.prepared_at))\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.prepared_at is null))\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.delivered_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.in_transit_at)\n",
        "\n",
        "        then network_print_job_event.shipped_at\n",
        "\n",
        "        else null\n",
        "\n",
        "      end\n",
        "\n",
        "    )) AS network_print_job_event_shipped_hour_of_day,\n",
        "    case\n",
        "        when ('free-customs' in UNNEST(shipment_delivery_terms.tag_list)) = true then 'Free'\n",
        "        when ('customs-risk' in UNNEST(shipment_delivery_terms.tag_list)) = true then 'DDP with risk'\n",
        "        when (shipment_delivery_terms.payment_type is not null and shipment_delivery_terms.payment_type = 'DDP') = true then 'DDP'\n",
        "        when (shipment_delivery_terms.payment_type is not null and shipment_delivery_terms.payment_type = 'DDU' and not ('free-customs' in UNNEST(shipment_delivery_terms.tag_list))) = true then 'DDU'\n",
        "        else null\n",
        "      end\n",
        "     AS shipment_delivery_terms_delivery_terms,\n",
        "        (DATE(tracking_status_log_min_date_out_for_delivery.min_event_date_out_for_delivery )) AS tracking_status_log_min_date_out_for_delivery_out_for_delivery_min_date,\n",
        "        (DATE(tracking_status_log_min_delivered_date.min_event_date_delivered )) AS tracking_status_log_min_delivered_date_delivered_min_date,\n",
        "        (DATE(tracking_status_log_min_date_in_transit.min_event_date_in_transit )) AS tracking_status_log_min_date_in_transit_in_transit_min_date,\n",
        "    network_package.package_id  AS network_package_package_id\n",
        "FROM network_print_job\n",
        "LEFT JOIN network_package ON network_print_job.package_id = network_package.package_id\n",
        "LEFT JOIN pgsql_printcloud_view.info_print_house  AS network_print_house ON network_package.print_house_id = network_print_house.print_house_id\n",
        "LEFT JOIN network_product_mapping_groups ON network_print_job.product_uid = network_product_mapping_groups.product_uid\n",
        "LEFT JOIN network_print_job_event ON network_print_job_event.print_job_id = network_print_job.print_job_id\n",
        "LEFT JOIN tracking_package ON cast(network_package.package_id as string) = tracking_package.PackageID\n",
        "LEFT JOIN tracking_trail ON tracking_package.ID = tracking_trail.PackageTrackingID\n",
        "LEFT JOIN tracking_status_log ON tracking_trail.ID = tracking_status_log.AuditTrailID\n",
        "LEFT JOIN tracking_status_log_min_delivered_date ON tracking_status_log.PackageID = tracking_status_log_min_delivered_date.PackageID\n",
        "LEFT JOIN tracking_status_log_min_date_in_transit ON tracking_status_log.PackageID = tracking_status_log_min_date_in_transit.PackageID\n",
        "LEFT JOIN tracking_status_log_min_date_out_for_delivery ON tracking_status_log.PackageID = tracking_status_log_min_date_out_for_delivery.PackageID\n",
        "LEFT JOIN pgsql_printcloud_view.public_shipment_data  AS network_shipment_data ON network_package.shipment_id = network_shipment_data.shipment_id\n",
        "LEFT JOIN shipment_method ON network_shipment_data.method_id = shipment_method.method_id\n",
        "LEFT JOIN pgsql_shipment_service_view.public_providers  AS shipment_provider ON shipment_method.provider_id = shipment_provider.provider_id\n",
        "INNER JOIN pgsql_shipment_service_view.public_countries  AS shipment_country_to ON network_shipment_data.country_code = shipment_country_to.iso_code\n",
        "LEFT JOIN shipment_zone_postcode_range ON network_shipment_data.zip >= shipment_zone_postcode_range.postcode_min and\n",
        "      network_shipment_data.zip <= shipment_zone_postcode_range.postcode_max and\n",
        "      shipment_country_to.country_id = shipment_zone_postcode_range.country_id and\n",
        "      shipment_zone_postcode_range.has_postcode_range = true\n",
        "      --06-Apr-2022 Mahesh:Added for Transit time analysis\n",
        "      and network_print_house.name = shipment_zone_postcode_range.print_house\n",
        "      and (case\n",
        "          when shipment_method.is_enabled = false then concat(shipment_provider.title,\" (not enabled)\")\n",
        "          else shipment_provider.title end) = shipment_zone_postcode_range.shipment_provider_name\n",
        "      and shipment_method.title = shipment_zone_postcode_range.shipment_method_name\n",
        "\n",
        "INNER JOIN shipment_country_zone ON shipment_zone_postcode_range.shipment_country_zone_id = shipment_country_zone.shipment_country_zone_id\n",
        "      or (\n",
        "        shipment_country_to.country_id = shipment_country_zone.country_id\n",
        "        --06-Apr-2022 Mahesh:Added for Transit time analysis\n",
        "        and network_print_house.name = shipment_country_zone.print_house\n",
        "        and (case\n",
        "          when shipment_method.is_enabled = false then concat(shipment_provider.title,\" (not enabled)\")\n",
        "          else shipment_provider.title end) = shipment_country_zone.shipment_provider_name\n",
        "        and shipment_method.title = shipment_country_zone.shipment_method_name\n",
        "        ----\n",
        "        and (\n",
        "          network_shipment_data.state_code = shipment_country_zone.administrative_area_level_1 or\n",
        "          network_shipment_data.city = shipment_country_zone.city or (\n",
        "            shipment_country_zone.administrative_area_level_1 is null and\n",
        "            shipment_country_zone.city is null\n",
        "          )\n",
        "        ) and\n",
        "        shipment_country_zone.has_postcode_range = false\n",
        "      )\n",
        "\n",
        "LEFT JOIN google_sheets_us.api_country_mapping  AS network_shipment_data_country ON network_shipment_data.country_code = network_shipment_data_country.country_code\n",
        "INNER JOIN pgsql_shipment_service_view.public_countries  AS shipment_country_from ON network_print_house.country_id = shipment_country_from.iso_code\n",
        "LEFT JOIN pgsql_shipment_service_view.public_delivery_terms  AS shipment_delivery_terms ON shipment_country_from.iso_code = shipment_delivery_terms.country_from_iso_code and\n",
        "      shipment_country_to.iso_code = shipment_delivery_terms.country_to_iso_code and\n",
        "      network_shipment_data.method_id = shipment_delivery_terms.method_id\n",
        "\n",
        "WHERE ((( case\n",
        "\n",
        "        when\n",
        "\n",
        "          (network_print_job_event.shipped_at = network_print_job_event.last_event_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at >= network_print_job_event.printed_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.shipped_at >= network_print_job_event.prepared_at))\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.prepared_at is null))\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.delivered_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.in_transit_at)\n",
        "\n",
        "        then network_print_job_event.shipped_at\n",
        "\n",
        "        else null\n",
        "\n",
        "      end\n",
        "\n",
        "     ) >= ((TIMESTAMP_ADD(TIMESTAMP_TRUNC(CURRENT_TIMESTAMP(), DAY), INTERVAL -1 DAY))) AND ( case\n",
        "\n",
        "        when\n",
        "\n",
        "          (network_print_job_event.shipped_at = network_print_job_event.last_event_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at >= network_print_job_event.printed_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.shipped_at >= network_print_job_event.prepared_at))\n",
        "\n",
        "          or\n",
        "\n",
        "          ((network_print_job_event.printed_at is null) and (network_print_job_event.prepared_at is null))\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.delivered_at)\n",
        "\n",
        "          or\n",
        "\n",
        "          (network_print_job_event.shipped_at <= network_print_job_event.in_transit_at)\n",
        "\n",
        "        then network_print_job_event.shipped_at\n",
        "\n",
        "        else null\n",
        "\n",
        "      end\n",
        "\n",
        "     ) < ((TIMESTAMP_ADD(TIMESTAMP_ADD(TIMESTAMP_TRUNC(CURRENT_TIMESTAMP(), DAY), INTERVAL -1 DAY), INTERVAL 2 DAY))))) AND ((( tracking_status_log_min_date_in_transit.min_event_date_in_transit  ) IS NOT NULL)) AND (shipment_country_zone.shipment_method_name ) = 'DHL Global Parcel'\n",
        "GROUP BY\n",
        "    1,\n",
        "    2,\n",
        "    3,\n",
        "    4,\n",
        "    5,\n",
        "    6,\n",
        "    7,\n",
        "    8,\n",
        "    9,\n",
        "    10,\n",
        "    11,\n",
        "    12,\n",
        "    13,\n",
        "    14,\n",
        "    15,\n",
        "    16,\n",
        "    17,\n",
        "    18\n",
        "ORDER BY\n",
        "    6 DESC\n",
        "\n",
        "\n",
        "  \n",
        "\"\"\", bq_client)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare df for prediction"
      ],
      "metadata": {
        "id": "ht5NSg3iGB2J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tsa6RwvFsqp_"
      },
      "outputs": [],
      "source": [
        "# include (flag) holidays into the data frame \n",
        "\n",
        "\n",
        "df_prediction.columns = ['order_day_ind','order_day','PH','Shipment_Method','Product','Shipped_Date','Shipping_Type','Zone','E_Country','Country','Shipping_day_index','Shipping_day','Shipping_hour','Term','out_of_delivery_min_date','delivery_min_date','in_transit_min_date','package_id']\n",
        "df1 = df_prediction\n",
        "Country_list = df1['Country'].to_list()\n",
        "Country_list = list(dict(zip(Country_list,range(0,len(Country_list)))).keys())\n",
        "\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "import holidays\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from pandas.tseries.offsets import BusinessDay\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "Germany1 = []\n",
        "France1 = []\n",
        "Netherlands1 = []\n",
        "Denmark1 = []\n",
        "Luxembourg1 = []\n",
        "Italy1 = []\n",
        "Sweden1 = []\n",
        "Portugal1 = []\n",
        "Czechia1 = [] #Czech Republic = []\n",
        "df1['Country'] = df1['Country'].replace('Czech Republic','Czechia')\n",
        "Belgium1 = []\n",
        "Austria1 = []\n",
        "Bulgaria1 = []\n",
        "Slovakia1 = [] #Slovak Republic\n",
        "df1['Country'] = df1['Country'].replace('Slovak Republic','Slovakia')\n",
        "Ireland1 = []\n",
        "Canada1 = []\n",
        "UK1 = []\n",
        "df1['Country'] = df1['Country'].replace('United Kingdom','UK')\n",
        "Switzerland1 = []\n",
        "Greece1 = []\n",
        "Poland1= []\n",
        "\n",
        "c_list = ['Poland','Greece','Switzerland','UK','Germany','France','Netherlands','Denmark','Luxembourg','Italy','Sweden','Portugal','Czechia','Belgium','Austria','Bulgaria','Slovakia','Slovakia','Ireland','Canada']\n",
        "\n",
        "for holiday in holidays.Germany(years=[2019,2020,2021,2022]).items():\n",
        "  Germany1.append(holiday[0])\n",
        "for holiday in holidays.France(years=[2019,2020,2021,2022]).items():\n",
        "  France1.append(holiday[0])\n",
        "for holiday in holidays.Netherlands(years=[2019,2020,2021,2022]).items():\n",
        "  Netherlands1.append(holiday[0])\n",
        "for holiday in holidays.Denmark(years=[2019,2020,2021,2022]).items():\n",
        "  Denmark1.append(holiday[0])\n",
        "for holiday in holidays.Luxembourg(years=[2019,2020,2021,2022]).items():\n",
        "  Luxembourg1.append(holiday[0])\n",
        "for holiday in holidays.Italy(years=[2019,2020,2021,2022]).items():\n",
        "  Italy1.append(holiday[0])\n",
        "for holiday in holidays.Sweden(years=[2019,2020,2021,2022]).items():\n",
        "  Sweden1.append(holiday[0])\n",
        "for holiday in holidays.Portugal(years=[2019,2020,2021,2022]).items():\n",
        "  Portugal1.append(holiday[0])\n",
        "for holiday in holidays.Czechia(years=[2019,2020,2021,2022]).items():\n",
        "  Czechia1.append(holiday[0])\n",
        "for holiday in holidays.Belgium(years=[2019,2020,2021,2022]).items():\n",
        "  Belgium1.append(holiday[0])\n",
        "for holiday in holidays.Austria(years=[2019,2020,2021,2022]).items():\n",
        "  Austria1.append(holiday[0])\n",
        "for holiday in holidays.Bulgaria(years=[2019,2020,2021,2022]).items():\n",
        "  Bulgaria1.append(holiday[0])\n",
        "for holiday in holidays.Ireland(years=[2019,2020,2021,2022]).items():\n",
        "  Ireland1.append(holiday[0])\n",
        "for holiday in holidays.Canada(years=[2019,2020,2021,2022]).items():\n",
        "  Canada1.append(holiday[0])\n",
        "for holiday in holidays.Poland(years=[2019,2020,2021,2022]).items():\n",
        "  Poland1.append(holiday[0])\n",
        "for holiday in holidays.UK(years=[2019,2020,2021,2022]).items():\n",
        "  UK1.append(holiday[0])\n",
        "for holiday in holidays.Switzerland(years=[2019,2020,2021,2022]).items():\n",
        "  Switzerland1.append(holiday[0])\n",
        "for holiday in holidays.Greece(years=[2019,2020,2021,2022]).items():\n",
        "  Greece1.append(holiday[0])\n",
        "\n",
        "class Holidays_c:\n",
        "  def __init__(self, country):\n",
        "    self.country = country\n",
        "\n",
        "Germany = Holidays_c(Germany1)\n",
        "France = Holidays_c(France1)\n",
        "Netherlands = Holidays_c(Netherlands1)\n",
        "Denmark = Holidays_c(Denmark1)\n",
        "Luxembourg = Holidays_c(Luxembourg1)\n",
        "Italy = Holidays_c(Italy1)\n",
        "Sweden = Holidays_c(Sweden1) \n",
        "Portugal = Holidays_c(Portugal1)\n",
        "Czechia = Holidays_c(Czechia1) \n",
        "Belgium = Holidays_c(Belgium1)\n",
        "Austria = Holidays_c(Austria1)\n",
        "Bulgaria = Holidays_c(Bulgaria1)\n",
        "Slovakia = Holidays_c(Slovakia1) \n",
        "Ireland = Holidays_c(Ireland1)\n",
        "Canada = Holidays_c(Canada1)\n",
        "Poland = Holidays_c(Poland1)\n",
        "Switzerland = Holidays_c(Switzerland1)\n",
        "Greece = Holidays_c(Greece1)\n",
        "UK = Holidays_c(UK1)\n",
        "\n",
        "# include (flag) holidays into the data frame \n",
        "def get_holiday(co, sd):\n",
        "  date_format = \"%Y-%m-%d\"\n",
        "  for x in eval(co).country:\n",
        "    if datetime.strptime(str(x), date_format) == datetime.strptime(str(sd), date_format) + timedelta(days=1):\n",
        "      h1 = 1\n",
        "      break\n",
        "  else:\n",
        "    h1 = 0\n",
        "  return h1\n",
        "\n",
        "\n",
        "def add_holidays(co, sd):\n",
        "  if co in c_list:\n",
        "    h11 = get_holiday(co,sd)\n",
        "  else:\n",
        "    h11 = int(0)\n",
        "  return h11\n",
        "\n",
        "def get_holiday2(co, sd):\n",
        "  date_format = \"%Y-%m-%d\"\n",
        "  for x in eval(co).country:\n",
        "    if datetime.strptime(str(x), date_format) == datetime.strptime(str(sd), date_format) + timedelta(days=2):\n",
        "      h1 = 1\n",
        "      break\n",
        "  else:\n",
        "    h1 = 0\n",
        "  return h1\n",
        "\n",
        "\n",
        "def add_holidays2(co, sd):\n",
        "  if co in c_list:\n",
        "    h11 = get_holiday2(co,sd)\n",
        "  else:\n",
        "    h11 = int(0)\n",
        "  return h11\n",
        "\n",
        "def get_holiday3(co, sd):\n",
        "  date_format = \"%Y-%m-%d\"\n",
        "  for x in eval(co).country:\n",
        "    if datetime.strptime(str(x), date_format) == datetime.strptime(str(sd), date_format) + timedelta(days=3):\n",
        "      h1 = 1\n",
        "      break\n",
        "  else:\n",
        "    h1 = 0\n",
        "  return h1\n",
        "\n",
        "\n",
        "def add_holidays3(co, sd):\n",
        "  if co in c_list:\n",
        "    h11 = get_holiday3(co,sd)\n",
        "  else:\n",
        "    h11 = int(0)\n",
        "  return h11\n",
        "\n",
        "def get_holiday4(co, sd):\n",
        "  date_format = \"%Y-%m-%d\"\n",
        "  for x in eval(co).country:\n",
        "    if datetime.strptime(str(x), date_format) == datetime.strptime(str(sd), date_format) + timedelta(days=4):\n",
        "      h1 = 1\n",
        "      break\n",
        "  else:\n",
        "    h1 = 0\n",
        "  return h1\n",
        "\n",
        "\n",
        "def add_holidays4(co, sd):\n",
        "  if co in c_list:\n",
        "    h11 = get_holiday4(co,sd)\n",
        "  else:\n",
        "    h11 = int(0)\n",
        "  return h11\n",
        "\n",
        "df1['holiday1'] = df1.apply(lambda x: add_holidays(x.Country,x.Shipped_Date), axis = 1)\n",
        "df1['holiday2'] = df1.apply(lambda x: add_holidays2(x.Country,x.Shipped_Date), axis = 1)\n",
        "df1['holiday3'] = df1.apply(lambda x: add_holidays3(x.Country,x.Shipped_Date), axis = 1)\n",
        "df1['holiday4'] = df1.apply(lambda x: add_holidays4(x.Country,x.Shipped_Date), axis = 1)\n",
        "\n",
        "\n",
        "df1['Country_PH'] = df1['PH'].apply(lambda x: 'Germany' if x[0:2] == 'DE' else ('Czechia' if x[0:2] == 'CZ' else 'None'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEbThtbwte9i"
      },
      "outputs": [],
      "source": [
        "df_pre = df1[['PH', 'Shipping_Type', 'Zone', 'Country', 'order_day_ind',\n",
        "       'Shipping_day_index', 'holiday1', 'holiday2', 'holiday3', 'holiday4',\n",
        "       'Shipping_hour','Product']]\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imFrJeZiuAkU"
      },
      "source": [
        "# Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from joblib import dump, load\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Models/model_v1.pkl', 'rb') as file:\n",
        "    s = pickle.load(file)\n",
        "\n",
        "y_new_pre = s.predict(df_pre)"
      ],
      "metadata": {
        "id": "GJYqEtrPYIiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef4cNX57wadq"
      },
      "source": [
        "# Data Table with Prediction for BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K23IawcdZTXE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "df_prediction['Prediction'] = [math.ceil(x) for x in list(y_new_pre)]\n",
        "df_prediction_BQ = df_prediction[['package_id','Prediction']]\n",
        "prediction_late_packages_csv = df_prediction_BQ.to_csv(index = False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Stored_Model: Logistic_Regression_Pipeline",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}